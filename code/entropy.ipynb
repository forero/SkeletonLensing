{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_id=100, nu_cut=1.0, beta=1.0, make_plot=False):\n",
    "\n",
    "    peak_name = \"map{:d}_100deg2_sl2.5_GSN_peaks.txt\".format(file_id)\n",
    "    peak_file = os.path.join(\"../data/\", peak_name)\n",
    "    all_peak_data = np.loadtxt(peak_file)\n",
    "\n",
    "    # significance cut\n",
    "    ii = all_peak_data[:,0]> nu_cut\n",
    "    peak_data = all_peak_data[ii]\n",
    "\n",
    "    peak_pos_file = peak_file.replace(\"map\", \"pos\")\n",
    "    np.savetxt(peak_pos_file, peak_data[:,1:])\n",
    "\n",
    "    beta = 1.0\n",
    "    out_filename = \"../data/beta_{:.1f}_nu_{:.1f}_{}\".format(beta, nu_cut, peak_name)\n",
    "\n",
    "\n",
    "    skel = \"/Users/forero/Applications/ngl-beta/build/binsrc/./getNeighborGraph \"\n",
    "\n",
    "    if not os.path.exists(out_filename):\n",
    "        cmd = \"{} -d 2 -i {} -b {} -o > {}\".format(skel, peak_pos_file, beta, out_filename)\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "    \n",
    "    # read in the pairs\n",
    "    point_data = np.loadtxt(peak_pos_file)\n",
    "    beta_data = np.int_(np.loadtxt(out_filename))\n",
    "\n",
    "    # remove the duplicate points using the fact that the first column is ordered in ngl-beta\n",
    "    ii = beta_data[:,0]<beta_data[:,1]\n",
    "    beta_data = beta_data[ii]\n",
    "\n",
    "    n_points = len(point_data)\n",
    "    print(n_points)\n",
    "\n",
    "    # Flattend and count links\n",
    "    beta_data_flat = beta_data.flatten()\n",
    "    beta_link_count = Counter(Counter(beta_data_flat).values())\n",
    "\n",
    "    # Count how many points have zero links\n",
    "    unique_beta_id = len(set(beta_data_flat))\n",
    "    if (n_points - unique_beta_id)>0:\n",
    "        beta_link_count[0] = n_points - unique_beta_id\n",
    "\n",
    "\n",
    "\n",
    "    assert np.sum(list(beta_link_count.values()))==n_points\n",
    "    # compute probability array\n",
    "    proba = []\n",
    "    total_link = np.sum(list(beta_link_count.values()))\n",
    "    for k in beta_link_count:\n",
    "        #print(k, beta_link_count[k]/total_link)\n",
    "        proba.append(beta_link_count[k]/total_link)\n",
    "    proba = np.array(proba)\n",
    "    print(proba, proba.sum())\n",
    "    entropy = np.sum(-proba*np.log(proba)/np.log10(2))\n",
    "    print('Entropy', entropy)\n",
    "    mean_conections = len(beta_data)/len(point_data)\n",
    "    print('Mean connections', mean_conections)\n",
    "\n",
    "    # compute the distances\n",
    "    delta_x  = point_data[beta_data[:,0],0] - point_data[beta_data[:,1],0]\n",
    "    delta_y = point_data[beta_data[:,0],1] - point_data[beta_data[:,1],1]\n",
    "    distance = np.sqrt(delta_x**2 + delta_y**2)\n",
    "    #_ = plt.hist(distance)\n",
    "    normed_mean_distance = np.mean(distance)/np.std(distance)\n",
    "\n",
    "\n",
    "    # plot the skeleton\n",
    "    if make_plot:\n",
    "        title = r\"$\\beta={:.1f}$, $\\nu>{:.1f}$, Entropy={:.2f} Sh, $\\langle l\\rangle / \\sigma_l = {:.2f}$, $\\kappa={:1.f}$\".format(\n",
    "            beta, nu_cut, entropy, normed_mean_distance, mean_connections)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        for p in beta_data:\n",
    "            #print(p)\n",
    "            plt.plot(point_data[p,0], point_data[p,1], c='black')\n",
    "        #plt.scatter(all_peak_data[:,1], all_peak_data[:,2],c=all_peak_data[:,0], alpha=0.4)\n",
    "        plt.scatter(peak_data[:,1], peak_data[:,2],c='black')\n",
    "        plt.axis('scaled')\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(4) / np.log10(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
